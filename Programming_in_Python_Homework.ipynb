{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VarvaraGm/Python_ALaTA_2022/blob/main/Programming_in_Python_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "17743a95",
      "metadata": {
        "id": "17743a95"
      },
      "outputs": [],
      "source": [
        "# opening and reading the file with my text\n",
        "with open ('/content/text for python.txt', 'r') as f: \n",
        "    review_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4a6fa710",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a6fa710",
        "outputId": "33958efa-9381-4b76-cf24-094813dedc4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kropp pulls out a letter.\n",
            "\"Kantorek sends you all his best wishes.\"\n",
            "We laugh.\n",
            "Muller throws his cigarette away and says: \"I wish he was here.\"\n",
            "Kantorek had been our schoolmaster, a stern little man in a grey tailcoat, with a face like a shrew mouse.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# importing tokenize functions and the stemmer from nltk library\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# setting a variable\n",
        "porter = PorterStemmer() \n",
        "\n",
        "# spliting the first five sentences\n",
        "sentences = sent_tokenize(review_text) \n",
        "\n",
        "for s in sentences[:5]:\n",
        "    print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fed01feb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fed01feb",
        "outputId": "12affb9e-39a8-4644-918f-146ff28aa33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kropp --> kropp\n",
            "pulls --> pull\n",
            "out --> out\n",
            "a --> a\n",
            "letter --> letter\n",
            ". --> .\n",
            "`` --> ``\n",
            "Kantorek --> kantorek\n",
            "sends --> send\n",
            "you --> you\n"
          ]
        }
      ],
      "source": [
        "# getting tokens of every word from these sentences\n",
        "tokens = [] \n",
        "\n",
        "for s in sentences[:5]:\n",
        "    tokens.extend(word_tokenize(s))\n",
        "\n",
        "# getting the stems of these tokens    \n",
        "porter_stems = [porter.stem(w) for w in tokens] \n",
        "\n",
        "for i in range(10):\n",
        "    print(f'{tokens[i]} --> {porter_stems[i]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b77e9a06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b77e9a06",
        "outputId": "a4485ee0-1f23-403f-8638-3993b1166fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kropp --> kropp\n",
            "pulls --> pull\n",
            "out --> out\n",
            "a --> a\n",
            "letter --> letter\n",
            ". --> .\n",
            "`` --> ``\n",
            "Kantorek --> kantorek\n",
            "sends --> send\n",
            "you --> you\n"
          ]
        }
      ],
      "source": [
        "# importing the other stemmer from nltk\n",
        "from nltk.stem.snowball import SnowballStemmer \n",
        "\n",
        "snowball = SnowballStemmer(\"english\") \n",
        "\n",
        "snowball_stems = [snowball.stem(t) for t in tokens]\n",
        "\n",
        "for i in range(10):\n",
        "    print(f'{tokens[i]} --> {snowball_stems[i]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "55fd8f94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55fd8f94",
        "outputId": "9009eee2-cbd1-40a0-9e8c-e287625fdf91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Naturally', 'ADV'), ('we', 'PRON'), ('could', 'VERB'), ('not', 'ADV'), ('blame', 'VERB'), ('Kantorek', 'NOUN'), ('for', 'ADP'), ('this', 'DET'), ('.', '.'), ('There', 'DET'), ('were', 'VERB'), ('thousands', 'NOUN'), ('of', 'ADP'), ('Kantoreks', 'NOUN'), (',', '.'), ('all', 'DET'), ('of', 'ADP'), ('whom', 'PRON'), ('were', 'VERB'), ('convinced', 'VERB'), ('that', 'ADP'), ('they', 'PRON'), ('were', 'VERB'), ('acting', 'VERB'), ('for', 'ADP'), ('the', 'DET'), ('best', 'ADJ'), ('-', '.'), ('in', 'ADP'), ('a', 'DET'), ('way', 'NOUN'), ('that', 'ADP'), ('cost', 'VERB'), ('them', 'PRON'), ('nothing', 'NOUN'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ],
      "source": [
        "# lemmatization\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "# importing the lemmatizer from nltk library\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"Naturally we could not blame Kantorek for this. There were thousands of Kantoreks, all of whom were convinced that they were acting for the best - in a way that cost them nothing.\"\n",
        "punctuations = \"?:!.,;-\"\n",
        "\n",
        "# applying pos_tag function \n",
        "sentence_words = nltk.pos_tag(nltk.word_tokenize(sentence), tagset = 'universal') \n",
        "\n",
        "print(sentence_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09ba0238",
      "metadata": {
        "id": "09ba0238"
      },
      "outputs": [],
      "source": [
        "# iterating through every tuple in our list\n",
        "# removing punctuation\n",
        "for t in sentence_words:\n",
        "    if t[0] in punctuations:\n",
        "        sentence_words.remove(t)\n",
        "\n",
        "# converting universal pos tags into the acceptable ones for our lemmatize function\n",
        "# creating a dictionary for this \n",
        "pos_tags_dict = {'NOUN': 'n', 'VERB': 'v', 'ADJ': 'a', 'ADV': 'r'}\n",
        "\n",
        "sentence_words \n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "# creating a loop to change the pos tags\n",
        "for t in sentence_words:\n",
        "    pos_tag = pos_tags_dict.get(t[1], 'n')\n",
        "    # if a tag is not in the dictionary we get 'n' as the default tag for the lemmatizer\n",
        "    print (\"{0:20}{1:20}\".format(t[0], wordnet_lemmatizer.lemmatize(word = t[0], pos = pos_tag)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d62999e",
      "metadata": {
        "id": "3d62999e"
      },
      "outputs": [],
      "source": [
        "# lemmatization with spacy\n",
        "\n",
        "import spacy\n",
        "\n",
        "# loading the corpus\n",
        "nlp = spacy.load(\"en_core_web_sm\") \n",
        "\n",
        "# creating the lists for lemmas and tokens\n",
        "spacy_lemmas = []\n",
        "spacy_tokens = []\n",
        "\n",
        "# preprocessing the sentences\n",
        "for s in sentences:\n",
        "  doc = nlp(s)\n",
        "\n",
        "  # extracting and adding tokens and lemmas to the lists\n",
        "  for token in doc:\n",
        "    spacy_tokens.append(token.text)\n",
        "    spacy_lemmas.append(token.lemma_)\n",
        "    \n",
        "for i in range(20):\n",
        "  print(f'{spacy_tokens[i]} --> {spacy_lemmas[i]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keyword extraction\n",
        "\n",
        "my_text = \"\"\"\n",
        "Kropp pulls out a letter. \"Kantorek sends you all his best wishes.\"\n",
        "We laugh. Muller throws his cigarette away and says: \"I wish he was here.\"\n",
        "Kantorek had been our schoolmaster, a stern little man in a grey tailcoat, with a face like a shrew mouse. He was about the same size as Corporal Himmelstoss, the \"terror of Klosterberg.\" It is very queer that the unhappiness of the world is so often brought on by small men. They are so much more energetic and uncompromising than the big fellows. I have always taken good care to keep out of sections with small company commanders. They are mostly confounded little martinets.\n",
        "During drill-time Kantorek gave us long lectures until the whole of our class went, under his shepherding, to the District Commandant and volunteered. I can see him now, as he used to glare at us through his spectacles and say in a moving voice: \"Won't you join up, Comrades?\"\n",
        "These teachers always carry their feelings ready in their waistcoat pockets, and trot them out by the hour. But we didn't think of that then.\n",
        "There was, indeed, one of us who hesitated and did not want to fall into line. That was Joseph Behm, a plump, homely fellow. But he did allow himself to be persuaded, otherwise he would have been ostracised. And perhaps more of us thought as he did, but no one could very well stand out, because at that time even one's parents were ready with the word \"coward\"; no one had the vaguest idea what we were in for. The wisest were just the poor and simple people. They knew the war to be a misfortune, whereas those who were better off, and should have been able to see more clearly what the consequences would be, were beside themselves with joy.\n",
        "Katczinsky said that was a result of their upbringing. It made them stupid. And what Kat said, he had thought about.\n",
        "Strange to say, Behm was one of the first to fall. He got hit in the eye during an attack, and we left him lying for dead. We couldn't bring him with us, because we had to come back helter-skelter. In the afternoon suddenly we heard him call, and saw him crawling about in No Man's Land. He had only been knocked unconscious. Because he could not see, and was mad with pain, he failed to keep under cover, and so was shot down before anyone could go and fetch him in.\n",
        "Naturally we couldn't blame Kantorek for this. Where would the world be if one brought every man to book? There were thousands of Kantoreks, all of whom were convinced that they were acting for the best - in a way that cost them nothing.\n",
        "And that is why they let us down so badly.\n",
        "For us lads of eighteen they ought to have been mediators and guides to the world of maturity, the world of work, of duty, of culture, of progress - to the future. We often made fun of them and played jokes on them, but in our hearts we trusted them. The idea of authority, which they represented, was associated in our minds with a greater insight and a more humane wisdom. But the first death we saw shattered this belief. We had to recognise that our generation was more to be trusted than theirs.\n",
        "They surpassed us only in phrases and in cleverness. The first bombardment showed us our mistake, and under it the world as they had taught it to us broke in pieces.\n",
        "While they continued to write and talk, we saw the wounded and dying. While they taught that duty to one's country is the greatest thing, we already knew that death-throes are stronger. But for all that we were no mutineers, no deserters, no cowards - they were very free with all these expressions. We loved our country as much as they; we went courageously into every action; but also we distinguished the false from true, we had suddenly learned to see. And we saw that there was nothing of their world left. We were all at once terribly alone; and alone we must see it through.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Z6cuaYzqJ86I"
      },
      "id": "Z6cuaYzqJ86I",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making a model with keywords\n",
        "\n",
        "references = ['Kantorek', 'man', 'world', 'Behn', 'duty']"
      ],
      "metadata": {
        "id": "ISccWL2UK4VV"
      },
      "id": "ISccWL2UK4VV",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a function to count recall, precision and f1 formulas for the model\n",
        "def evaluate(keyphrases, references):\n",
        "    P = len(set(keyphrases) & set(references)) / len(keyphrases)\n",
        "    R = len(set(keyphrases) & set(references)) / len(references)\n",
        "    F = (2*P*R)/(P+R) if (P+R) > 0 else 0 \n",
        "    return (P, R, F)"
      ],
      "metadata": {
        "id": "JYjkZ14dLeRd"
      },
      "id": "JYjkZ14dLeRd",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractor = pke.unsupervised.TopicRank()\n",
        "extractor.load_document(input=my_text)\n",
        "grammar=\"NP: {<ADJ>*<NOUN|PROPN>+}\"\n",
        "extractor.grammar_selection(grammar=grammar)\n",
        "extractor.candidate_weighting()\n",
        "keyphrases = extractor.get_n_best(n=5, stemming=True)\n",
        "\n",
        "top5 = [candidate for candidate, weight in keyphrases]\n",
        "print(\"top-5 keyphrases:\", '; '.join(top5))\n",
        "\n",
        "\n",
        "P, R, F = evaluate(top5, references)\n",
        "print(\"P: {:.3f} R: {:.3f} F: {:.3f}\".format(P, R, F))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "ZY1Du9cnNFTp",
        "outputId": "43d3fae5-8cc3-4e95-8396-365a2a071869"
      },
      "id": "ZY1Du9cnNFTp",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-fa5b3a600c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NP: {<ADJ>*<NOUN|PROPN>+}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrammar_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_weighting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mkeyphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstemming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pke/unsupervised/graph_based/topicrank.py\u001b[0m in \u001b[0;36mcandidate_weighting\u001b[0;34m(self, threshold, method, heuristic)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# compute the word scores using random walk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagerank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.85\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# loop through the topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/networkx/algorithms/link_analysis/pagerank_alg.py\u001b[0m in \u001b[0;36mpagerank\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m     return pagerank_scipy(\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersonalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdangling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/networkx/algorithms/link_analysis/pagerank_alg.py\u001b[0m in \u001b[0;36mpagerank_scipy\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0mnodelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_scipy_sparse_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodelist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/networkx/convert_matrix.py\u001b[0m in \u001b[0;36mto_scipy_sparse_array\u001b[0;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdiag_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdiag_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoo_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'scipy.sparse' has no attribute 'coo_array'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36465cc6",
      "metadata": {
        "id": "36465cc6"
      },
      "outputs": [],
      "source": [
        "# keyword extraction YAKE!\n",
        "\n",
        "!pip install git+https://github.com/LIAAD/yake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yake import KeywordExtractor"
      ],
      "metadata": {
        "id": "Kwrbd_y4f3mA"
      },
      "id": "Kwrbd_y4f3mA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_text = \"\"\"\n",
        "Kropp pulls out a letter. \"Kantorek sends you all his best wishes.\"\n",
        "We laugh. Muller throws his cigarette away and says: \"I wish he was here.\"\n",
        "Kantorek had been our schoolmaster, a stern little man in a grey tailcoat, with a face like a shrew mouse. He was about the same size as Corporal Himmelstoss, the \"terror of Klosterberg.\" It is very queer that the unhappiness of the world is so often brought on by small men. They are so much more energetic and uncompromising than the big fellows. I have always taken good care to keep out of sections with small company commanders. They are mostly confounded little martinets.\n",
        "During drill-time Kantorek gave us long lectures until the whole of our class went, under his shepherding, to the District Commandant and volunteered. I can see him now, as he used to glare at us through his spectacles and say in a moving voice: \"Won't you join up, Comrades?\"\n",
        "These teachers always carry their feelings ready in their waistcoat pockets, and trot them out by the hour. But we didn't think of that then.\n",
        "There was, indeed, one of us who hesitated and did not want to fall into line. That was Joseph Behm, a plump, homely fellow. But he did allow himself to be persuaded, otherwise he would have been ostracised. And perhaps more of us thought as he did, but no one could very well stand out, because at that time even one's parents were ready with the word \"coward\"; no one had the vaguest idea what we were in for. The wisest were just the poor and simple people. They knew the war to be a misfortune, whereas those who were better off, and should have been able to see more clearly what the consequences would be, were beside themselves with joy.\n",
        "Katczinsky said that was a result of their upbringing. It made them stupid. And what Kat said, he had thought about.\n",
        "Strange to say, Behm was one of the first to fall. He got hit in the eye during an attack, and we left him lying for dead. We couldn't bring him with us, because we had to come back helter-skelter. In the afternoon suddenly we heard him call, and saw him crawling about in No Man's Land. He had only been knocked unconscious. Because he could not see, and was mad with pain, he failed to keep under cover, and so was shot down before anyone could go and fetch him in.\n",
        "Naturally we couldn't blame Kantorek for this. Where would the world be if one brought every man to book? There were thousands of Kantoreks, all of whom were convinced that they were acting for the best - in a way that cost them nothing.\n",
        "And that is why they let us down so badly.\n",
        "For us lads of eighteen they ought to have been mediators and guides to the world of maturity, the world of work, of duty, of culture, of progress - to the future. We often made fun of them and played jokes on them, but in our hearts we trusted them. The idea of authority, which they represented, was associated in our minds with a greater insight and a more humane wisdom. But the first death we saw shattered this belief. We had to recognise that our generation was more to be trusted than theirs.\n",
        "They surpassed us only in phrases and in cleverness. The first bombardment showed us our mistake, and under it the world as they had taught it to us broke in pieces.\n",
        "While they continued to write and talk, we saw the wounded and dying. While they taught that duty to one's country is the greatest thing, we already knew that death-throes are stronger. But for all that we were no mutineers, no deserters, no cowards - they were very free with all these expressions. We loved our country as much as they; we went courageously into every action; but also we distinguished the false from true, we had suddenly learned to see. And we saw that there was nothing of their world left. We were all at once terribly alone; and alone we must see it through.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hvqkJ1NugBux"
      },
      "id": "hvqkJ1NugBux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kw_extractor = KeywordExtractor(lan=\"en\", n=1, top=5) \n",
        "\n",
        "keywords = kw_extractor.extract_keywords(text=my_text)\n",
        "keywords = [x for x, y in keywords]\n",
        "keywords"
      ],
      "metadata": {
        "id": "S9mbsT3cgOVv"
      },
      "id": "S9mbsT3cgOVv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}